{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2b62de",
   "metadata": {},
   "source": [
    "# ì „ì²˜ë¦¬\n",
    "\n",
    "- RMSE : 23724.4207\n",
    "- ë°ì´í„° : train_csv, test_csv, subway_feature, bus_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5399573",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/root/AI_STAGE/upstageailab-ml-competition-ml-2/1.Data/train.csv'\n",
    "test_path  = '/root/AI_STAGE/upstageailab-ml-competition-ml-2/1.Data/test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ ìœ„í•œ ë°ì´í„°ì…‹ í•©ì¹˜ê¸°\n",
    "\n",
    "train['data'] = 0\n",
    "test['data'] = 1\n",
    "concat = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¦„ ë°”ê¾¸ê¸°\n",
    "\n",
    "concat = concat.rename(columns={'ì „ìš©ë©´ì (ã¡)':'ì „ìš©ë©´ì '})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³¸ë²ˆ, ë¶€ë²ˆì˜ ê²½ìš° floatë¡œ ë˜ì–´ìˆì§€ë§Œ ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì˜ë¯¸ë¥¼ ê°€ì§€ë¯€ë¡œ object(string) í˜•íƒœë¡œ ë°”ê¾¸ê¸°\n",
    "concat_select['ë³¸ë²ˆ'] = concat_select['ë³¸ë²ˆ'].astype('str')\n",
    "concat_select['ë¶€ë²ˆ'] = concat_select['ë¶€ë²ˆ'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7861f1",
   "metadata": {},
   "source": [
    "### ê²°ì¸¡ì¹˜ íƒì§€ ë° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—´ ì „ì²´ë¥¼ ë„£ê³  ìŠ¤ìº”í•˜ê¸°\n",
    "\n",
    "for col in concat.columns:\n",
    "    nunique = concat[col].nunique(dropna=False)\n",
    "    missing_ratio = concat[col].isna().mean()\n",
    "    missing_count = concat[col].isnull().sum()\n",
    "    col_type = concat.dtypes[col]\n",
    "    print(f\"ğŸ“Œ {col:30} | ë°ì´í„°íƒ€ì…: {col_type} | ê³ ìœ ê°’: {nunique:6} | ê²°ì¸¡ê°œìˆ˜: {missing_count} | ê²°ì¸¡ë¥ : {missing_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ì¹˜ëŠ” ì•„ë‹Œë° ì˜ë¯¸ ì—†ëŠ” í˜•ì‹ì  ê°’ ì°¾ê¸°\n",
    "\n",
    "def detect_fake_nulls(df, suspect_values=['-', ' ', '', '.', 'ì—†ìŒ', 'nan']):\n",
    "    result = {}\n",
    "    for col in df.columns:\n",
    "        if concat[col].dtype == 'object':\n",
    "            val_counts = concat[col].value_counts(dropna=False)\n",
    "            found = val_counts[val_counts.index.isin(suspect_values)]\n",
    "            if not found.empty:\n",
    "                result[col] = found\n",
    "    return result\n",
    "\n",
    "fake_nulls = detect_fake_nulls(concat)\n",
    "for col, vals in fake_nulls.items():\n",
    "    print(f\"ğŸ” {col} ì»¬ëŸ¼ì—ì„œ ì˜ë¯¸ ì—†ëŠ” ê°’ ë°œê²¬:\")\n",
    "    print(vals)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ„ ì²˜ëŸ¼ ì•„ë¬´ ì˜ë¯¸ë„ ê°–ì§€ ì•ŠëŠ” ì¹¼ëŸ¼ì€ ê²°ì¸¡ì¹˜ì™€ ê°™ì€ ì—­í• ì„ í•˜ë¯€ë¡œ, np.nanìœ¼ë¡œ ì±„ì›Œ ê²°ì¸¡ì¹˜ë¡œ ì¸ì‹ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "concat['ë„ë¡œëª…'] = concat['ë„ë¡œëª…'].replace(' ', np.nan)\n",
    "concat['ë“±ê¸°ì‹ ì²­ì¼ì'] = concat['ë“±ê¸°ì‹ ì²­ì¼ì'].replace(' ', np.nan)\n",
    "concat['ê±°ë˜ìœ í˜•'] = concat['ê±°ë˜ìœ í˜•'].replace('-', np.nan)\n",
    "concat['ì¤‘ê°œì‚¬ì†Œì¬ì§€'] = concat['ì¤‘ê°œì‚¬ì†Œì¬ì§€'].replace('-', np.nan)\n",
    "concat['k-ì‹œí–‰ì‚¬'] = concat['k-ì‹œí–‰ì‚¬'].replace('.', np.nan)\n",
    "concat['k-ì‹œí–‰ì‚¬'] = concat['k-ì‹œí–‰ì‚¬'].replace('-', np.nan)\n",
    "concat['k-í™ˆí˜ì´ì§€'] = concat['k-í™ˆí˜ì´ì§€'].replace('ì—†ìŒ', np.nan)\n",
    "concat['k-í™ˆí˜ì´ì§€'] = concat['k-í™ˆí˜ì´ì§€'].replace('.', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(concat.shape[0] * 0.8) = 902475.2000000001\n",
    "# Nullê°’ì´ 90ë§Œê°œ ì´ìƒì¸ ì¹¼ëŸ¼ì€ ì‚­ì œí•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "print('* ê²°ì¸¡ì¹˜ê°€ 90ë§Œê°œ ì´í•˜ì¸ ë³€ìˆ˜ë“¤ :', list(concat.columns[concat.isnull().sum() <= 900000]))     # ë‚¨ê²¨ì§ˆ ë³€ìˆ˜ë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "print('* ê²°ì¸¡ì¹˜ê°€ 90ë§Œê°œ ì´ìƒì¸ ë³€ìˆ˜ë“¤ :', list(concat.columns[concat.isnull().sum() >= 900000]))\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ 90ë§Œê°œ ì´ìƒì¸ ê°’ê³¼ ì´í•˜ì§€ë§Œ í•„ìš”ì—†ëŠ” ê²ƒ ì œì™¸\n",
    "# í•„ìš”ì—†ì–´ ë³´ì´ëŠ” ê²ƒ : k-ì „í™”ë²ˆí˜¸, k-íŒ©ìŠ¤ë²ˆí˜¸, ì‚¬ìš©í—ˆê°€ì—¬ë¶€, ê´€ë¦¬ë¹„ ì—…ë¡œë“œ, k-ìˆ˜ì •ì¼ì\n",
    "\n",
    "valid_cols = concat.columns[concat.isnull().sum() <= 900000]\n",
    "exclude_cols = ['k-ì „í™”ë²ˆí˜¸', 'k-íŒ©ìŠ¤ë²ˆí˜¸', 'ì‚¬ìš©í—ˆê°€ì—¬ë¶€', 'ê´€ë¦¬ë¹„ ì—…ë¡œë“œ', 'k-ìˆ˜ì •ì¼ì']\n",
    "\n",
    "select = [col for col in valid_cols if col not in exclude_cols]\n",
    "concat_select = concat[select]\n",
    "\n",
    "concat.shape, concat_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db417df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¨¼ì €, ì—°ì†í˜• ë³€ìˆ˜ì™€ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìœ„ infoì— ë”°ë¼ ë¶„ë¦¬í•´ì£¼ê² ìŠµë‹ˆë‹¤.\n",
    "# ìˆ«ìí˜• ë¶„ë¦¬ pd.api.types.is_numeric_dtype\n",
    "con_columns = []\n",
    "cat_columns = []\n",
    "\n",
    "for column in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[column]):\n",
    "        con_columns.append(column)\n",
    "    else:\n",
    "        cat_columns.append(column)\n",
    "\n",
    "print(\"ì—°ì†í˜• ë³€ìˆ˜:\", con_columns)\n",
    "print(\"ë²”ì£¼í˜• ë³€ìˆ˜:\", cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™© ì‹œë¦¬ì¦ˆë¼ë¦¬ ìƒê´€ê´€ê³„ê°€ ìˆìŒ -> ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨\n",
    "# ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™© pca ì§„í–‰\n",
    "\n",
    "pca_cols = [\n",
    "    'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡ì´í•˜)',\n",
    "    'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)',\n",
    "    'k-85ã¡~135ã¡ì´í•˜'\n",
    "]\n",
    "pca_data = concat_select[pca_cols].fillna(0)  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ê²°ì¸¡ 0ìœ¼ë¡œ ëŒ€ì²´\n",
    "\n",
    "# pca ì§„í–‰í•  feature ì •ê·œí™”\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_pca_data = scaler.fit_transform(pca_data)\n",
    "\n",
    "# pca ì ìš©\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # 2ê°œ ì„±ë¶„ìœ¼ë¡œ ì¶•ì†Œ\n",
    "pca_components = pca.fit_transform(scaled_pca_data)\n",
    "\n",
    "# ì„¤ëª…ë ¥ ë³´ê¸°\n",
    "print(pca.explained_variance_ratio_)  # ì˜ˆ: [0.83, 0.16]\n",
    "\n",
    "# PCA ê²°ê³¼ ì €ì¥\n",
    "concat_select[\"ì„¸ëŒ€ë©´ì _PCA1\"] = pca_components[:, 0]\n",
    "concat_select[\"ì„¸ëŒ€ë©´ì _PCA2\"] = pca_components[:, 1]\n",
    "\n",
    "# ì›ë³¸ feature ì œê±°\n",
    "concat_select.drop(columns=pca_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë‹¤ìŒìœ¼ë¡œ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ìˆëŠ” feature ì œê±°\n",
    "\n",
    "drop_cols = ['k-ê´€ë¦¬ë¹„ë¶€ê³¼ë©´ì ','k-ì—°ë©´ì ','k-ì „ì²´ë™ìˆ˜']\n",
    "concat_select.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46cfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ì†í˜• ë³€ìˆ˜ ë™ ë‹¨ìœ„ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "# targetì€ ê±´ë“¤ì§€ ë§ì•„ë³´ì\n",
    "\n",
    "concat_select['êµ¬'] = concat_select['ì‹œêµ°êµ¬'].str.split().str[1]\n",
    "concat_select['ë™'] = concat_select['ì‹œêµ°êµ¬'].str.split().str[2]\n",
    "\n",
    "impute_targets = ['ê±´ì¶•ë©´ì ', 'ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'k-ì£¼ê±°ì „ìš©ë©´ì ', 'k-ì „ì²´ì„¸ëŒ€ìˆ˜']\n",
    "\n",
    "for col in impute_targets:\n",
    "    # 1ì°¨: ë™ ë‹¨ìœ„ í‰ê· \n",
    "    concat_select[col] = concat_select.groupby('ë™')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 2ì°¨: êµ¬ ë‹¨ìœ„ í‰ê·  (ë™ í‰ê· ì´ ì•ˆ ë˜ë©´ ì—¬ê¸°ì„œ)\n",
    "    concat_select[col] = concat_select.groupby('êµ¬')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 3ì°¨: ì „ì²´ í‰ê·  (êµ¬ í‰ê· ë„ ì•ˆ ë˜ë©´ ì—¬ê¸°ì„œ)\n",
    "    concat_select[col].fillna(concat_select[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0962f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "\n",
    "cat_with_na = [\n",
    "    'ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•', 'k-ì‹œí–‰ì‚¬', 'ì²­ì†Œë¹„ê´€ë¦¬í˜•íƒœ', 'k-ê±´ì„¤ì‚¬(ì‹œê³µì‚¬)',\n",
    "    'ê²½ë¹„ë¹„ê´€ë¦¬í˜•íƒœ', 'k-ë‹¨ì§€ë¶„ë¥˜(ì•„íŒŒíŠ¸,ì£¼ìƒë³µí•©ë“±ë“±)', 'ë‹¨ì§€ìŠ¹ì¸ì¼',\n",
    "    'k-ë³µë„ìœ í˜•', 'k-ì‚¬ìš©ê²€ì‚¬ì¼-ì‚¬ìš©ìŠ¹ì¸ì¼', 'ë‹¨ì§€ì‹ ì²­ì¼',\n",
    "    'k-ë‚œë°©ë°©ì‹', 'k-ê´€ë¦¬ë°©ì‹', 'k-ì„¸ëŒ€íƒ€ì…(ë¶„ì–‘í˜•íƒœ)',\n",
    "    'ê¸°íƒ€/ì˜ë¬´/ì„ëŒ€/ì„ì˜=1/2/3/4', 'ì•„íŒŒíŠ¸ëª…', 'ë„ë¡œëª…', 'ë²ˆì§€'\n",
    "]\n",
    "\n",
    "for col in cat_with_na:\n",
    "   \n",
    "    concat_select[col] = concat_select[col].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d584a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²”ì£¼í˜• featureë“¤ ê´€ê³„ ë³´ê¸°\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# CramÃ©r's V ê³„ì‚° í•¨ìˆ˜\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix, correction=False)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸\n",
    "cat_cols = cat_columns2  # ì´ë¯¸ ë‚˜ëˆˆ ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41060e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ë˜ë¨¸ìŠ¤ ë¸Œì´ ê¸°ì¤€ ê´€ê³„ìˆëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ ì œê±°\n",
    "\n",
    "drop_cat_cols = [\n",
    "    'ë³¸ë²ˆ',\n",
    "    'ë¶€ë²ˆ',\n",
    "    'ë„ë¡œëª…',\n",
    "    'ë‹¨ì§€ìŠ¹ì¸ì¼',\n",
    "    'ë‹¨ì§€ì‹ ì²­ì¼',\n",
    "    'k-ì„¸ëŒ€íƒ€ì…(ë¶„ì–‘í˜•íƒœ)',\n",
    "    'k-ê´€ë¦¬ë°©ì‹',\n",
    "    'k-ë‚œë°©ë°©ì‹',\n",
    "    'k-ë³µë„ìœ í˜•',\n",
    "    'ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•',\n",
    "    'ê²½ë¹„ë¹„ê´€ë¦¬í˜•íƒœ',\n",
    "    'ì²­ì†Œë¹„ê´€ë¦¬í˜•íƒœ',\n",
    "    'ê¸°íƒ€/ì˜ë¬´/ì„ëŒ€/ì„ì˜=1/2/3/4',\n",
    "]\n",
    "\n",
    "# ì œê±° ì ìš©\n",
    "concat_select.drop(columns=drop_cat_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e4a10",
   "metadata": {},
   "source": [
    "### ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬\n",
    "\n",
    "def detect_outliers_iqr(df, columns, iqr_scale=1.5):\n",
    "    outlier_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        if df[col].isnull().all():\n",
    "            continue\n",
    "\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - iqr_scale * IQR\n",
    "        upper_bound = Q3 + iqr_scale * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_count = outliers.shape[0]\n",
    "        outlier_ratio = outlier_count / df.shape[0] * 100\n",
    "\n",
    "        outlier_summary.append({\n",
    "            'ë³€ìˆ˜': col,\n",
    "            'ì´ìƒì¹˜ ê°œìˆ˜': outlier_count,\n",
    "            'ì´ìƒì¹˜ ë¹„ìœ¨(%)': round(outlier_ratio, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(outlier_summary).sort_values('ì´ìƒì¹˜ ë¹„ìœ¨(%)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cb947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ìƒì¹˜ ë¹„ìœ¨ ìƒìœ„ 5ê°œ ë³€ìˆ˜ ì¶”ì¶œ\n",
    "top_outlier_cols = outlier_df['ë³€ìˆ˜'].head(5)\n",
    "\n",
    "# pca ì„¤ëª…ë ¥ì´ ë†’ì§€ë„ ì•Šê³  ì´ìƒì¹˜ë„ ë§ì•„ì„œ pca ì œê±°\n",
    "# ì›ë³¸ k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜) ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "# 1. PCAë¡œ ë§Œë“  feature ì œê±°\n",
    "pca_cols = ['ì„¸ëŒ€ë©´ì _PCA1', 'ì„¸ëŒ€ë©´ì _PCA2']\n",
    "concat_select.drop(columns=pca_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# 2. ì›ë³¸ì—ì„œ íŠ¹ì • ë³€ìˆ˜ë§Œ ê°€ì ¸ì™€ì„œ ì¶”ê°€\n",
    "selected_feature = 'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)'\n",
    "concat_select[selected_feature] = concat[selected_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_selectê°€ ì•„ë‹Œ concatì—ì„œ ê°€ì ¸ì™€ì„œ ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "# concatì—ì„œ ê°€ì ¸ì˜¨ ì´ìœ  : concat_selectì—ì„œ pcaí•˜ë©´ì„œ feature ì§€ì›Œë²„ë¦¼\n",
    "\n",
    "concat_select['k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)'].isnull().sum()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ëŠ” ë™/êµ¬/ì „ì²´ í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "\n",
    "impute2_targets = ['k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)']\n",
    "\n",
    "for col in impute2_targets:\n",
    "    # 1ì°¨: ë™ ë‹¨ìœ„ í‰ê· \n",
    "    concat_select[col] = concat_select.groupby('ë™')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 2ì°¨: êµ¬ ë‹¨ìœ„ í‰ê·  (ë™ í‰ê· ì´ ì•ˆ ë˜ë©´ ì—¬ê¸°ì„œ)\n",
    "    concat_select[col] = concat_select.groupby('êµ¬')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 3ì°¨: ì „ì²´ í‰ê·  (êµ¬ í‰ê· ë„ ì•ˆ ë˜ë©´ ì—¬ê¸°ì„œ)\n",
    "    concat_select[col].fillna(concat_select[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead39b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™•ì¸\n",
    "# ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "con_columns_final = []\n",
    "cat_columns_final = []\n",
    "\n",
    "# concat_select ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬\n",
    "for col in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[col]):\n",
    "        con_columns_final.append(col)\n",
    "    else:\n",
    "        cat_columns_final.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fe719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì‹œ IQR í™•ì¸\n",
    "\n",
    "def detect_outliers_iqr(df, columns, iqr_scale=1.5):\n",
    "    outlier_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        if df[col].isnull().all():\n",
    "            continue\n",
    "\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - iqr_scale * IQR\n",
    "        upper_bound = Q3 + iqr_scale * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_count = outliers.shape[0]\n",
    "        outlier_ratio = outlier_count / df.shape[0] * 100\n",
    "\n",
    "        outlier_summary.append({\n",
    "            'ë³€ìˆ˜': col,\n",
    "            'ì´ìƒì¹˜ ê°œìˆ˜': outlier_count,\n",
    "            'ì´ìƒì¹˜ ë¹„ìœ¨(%)': round(outlier_ratio, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(outlier_summary).sort_values('ì´ìƒì¹˜ ë¹„ìœ¨(%)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ìƒì¹˜ ë¹„ìœ¨ ìƒìœ„ 5ê°œ ë³€ìˆ˜ ì¶”ì¶œ\n",
    "top_outlier_cols = outlier_df['ë³€ìˆ˜'].head(8)\n",
    "\n",
    "# ì´ìƒì¹˜ ì œê±° ëŒ€ì‹  í´ë¦½ ë°©ì‹ ì„ íƒ\n",
    "\n",
    "def clip_iqr(df, columns, k=1.5):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - k * IQR\n",
    "        upper = Q3 + k * IQR\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "    return df\n",
    "\n",
    "clip_cols = ['ê±´ì¶•ë©´ì ', 'ì „ìš©ë©´ì ', 'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)', 'k-ì „ì²´ì„¸ëŒ€ìˆ˜', 'ì£¼ì°¨ëŒ€ìˆ˜']\n",
    "\n",
    "concat_select = clip_iqr(concat_select, clip_cols)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
